<!DOCTYPE html>
<html dir="ltr" lang="en"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"><title>AlphaGoNaturePaper.pdf</title><link rel="stylesheet" type="text/css" href="AlphaGoNaturePaper_files/rsAC2dHMIOGu1Yq_NsJEu5C9lZJhj0C8UXew.css"></head><body class="ndfHFb-c4YZDc-qbOKL-OEVmcd"><script src="AlphaGoNaturePaper_files/cbgapi.loaded_0" nonce="zbdGeAsk/FGfcEQcPAQL4Q" async="" aria-hidden="true"></script><script type="text/javascript" charset="UTF-8" src="AlphaGoNaturePaper_files/mmain" nonce="zbdGeAsk/FGfcEQcPAQL4Q" aria-hidden="true"></script><script type="text/javascript" src="AlphaGoNaturePaper_files/client.js" nonce="zbdGeAsk/FGfcEQcPAQL4Q" aria-hidden="true" gapi_processed="true"></script><script type="text/javascript" nonce="zbdGeAsk/FGfcEQcPAQL4Q" aria-hidden="true">_init([["0",null,null,null,1,1,null,null,null,null,0,[1]
,0,null,null,"https://drive.google.com",null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,1,[["core-384-RC2","prod"]
,12,1,1]
,null,null,null,null,[null,null,null,null,"https://accounts.google.com/ServiceLogin?passive\u003d1209600\u0026continue\u003dhttps://drive.google.com/viewerng/viewer?url%3Dhttps://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf\u0026hl\u003den_US\u0026followup\u003dhttps://drive.google.com/viewerng/viewer?url%3Dhttps://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf",null,null,null,0]
,null,null,null,null,null,null,null,null,null,null,1,1,null,null,null,0,null,null,null,null,null,null,null,null,null,1]
,[null,"AlphaGoNaturePaper.pdf","/viewerng/thumb?ds\u003dAON1mFzfc5oZvLac4i352y0tPnYG3_FrbAryfgCo6N3y95lJm0xqLtVIHir0jJughNoYxPYDIpSnuVBuluST5whMtvsHrUdpONS_Qdw1vTjacdZj58F7KD6gpXLs50lNZ_N9j1sXTavEFSMfN_uaaWLy4MdivMi7wF_muGscG-UJChkUQQ6IVkMVAosXZeXxgMxZGVrBY6f349YSqVytt4ER1dSKY64xebjtnKR9WtKozeZvOajDrnFD7m2jNZXl189lV3SORgK3SYvXoa7Kp4e4NodR2cN-cE1JsHvQBFYCfUTzeI3Ov2U%3D\u0026ck\u003dlantern\u0026authuser\u0026w\u003d800\u0026webp\u003dtrue\u0026p\u003dproj",null,null,null,null,null,null,"/viewerng/upload?ds\u003dAON1mFzHiMu5-TzCgoXq4Rrq7dhVYeh_La8L-E1ES8tuJmILl6mlC7LGfAOOiNSAyn-dGmjvrRAWGy52Rbxgn9wU89_8QuoqeQAGsLVDqrS6CudS_4Fa2kRkQddCHMAziBZPCkhrKQ7Gy9cVwj3ANxUM559V6fIIrNBQgXQAneYFs5N6VI166m7BKahQE-ihwmqpLfifUUVLQKwnPIZ0YSC-J1lxpQ4fpMcNCnCmX20DcR_TNL4SqMZF1cEb9h6CWggZhU4Ph2hT9UzBQolU4qlUj-L1EVzKPX47xUStxG61f2vhS85TohU%3D\u0026ck\u003dlantern\u0026authuser\u0026p\u003dproj",null,"application/pdf",null,null,1,null,null,null,"https://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf",null,1,0,null,null,null,null,null,"/viewerng/standalone/refresh?url\u003dhttps://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf",[null,null,"meta?id\u003dACFrOgBafqcZgGM1tI-aj5_QZGO6ohzPaKICIa4iBrRGJezaZJ_IpVMFp7Z-SPRgX9ijpbe2ZuZHsNGpCQAiS1YDYTbl4bMCTlOmKdvhBTNkFdHq3EmvvBwCCvjvFLZ-PrmomEjoVo3Dg7tvepu2","img?id\u003dACFrOgBafqcZgGM1tI-aj5_QZGO6ohzPaKICIa4iBrRGJezaZJ_IpVMFp7Z-SPRgX9ijpbe2ZuZHsNGpCQAiS1YDYTbl4bMCTlOmKdvhBTNkFdHq3EmvvBwCCvjvFLZ-PrmomEjoVo3Dg7tvepu2","press?id\u003dACFrOgBafqcZgGM1tI-aj5_QZGO6ohzPaKICIa4iBrRGJezaZJ_IpVMFp7Z-SPRgX9ijpbe2ZuZHsNGpCQAiS1YDYTbl4bMCTlOmKdvhBTNkFdHq3EmvvBwCCvjvFLZ-PrmomEjoVo3Dg7tvepu2","status?id\u003dACFrOgBafqcZgGM1tI-aj5_QZGO6ohzPaKICIa4iBrRGJezaZJ_IpVMFp7Z-SPRgX9ijpbe2ZuZHsNGpCQAiS1YDYTbl4bMCTlOmKdvhBTNkFdHq3EmvvBwCCvjvFLZ-PrmomEjoVo3Dg7tvepu2","https://doc-0g-bk-apps-viewer.googleusercontent.com/viewer/secure/pdf/3nb9bdfcv3e2h2k1cmql0ee9cvc5lole/uukr45aq5fl4a2ija9k9520rgpknp00q/1552752675000/lantern/*/ACFrOgBafqcZgGM1tI-aj5_QZGO6ohzPaKICIa4iBrRGJezaZJ_IpVMFp7Z-SPRgX9ijpbe2ZuZHsNGpCQAiS1YDYTbl4bMCTlOmKdvhBTNkFdHq3EmvvBwCCvjvFLZ-PrmomEjoVo3Dg7tvepu2",null,"presspage?id\u003dACFrOgBafqcZgGM1tI-aj5_QZGO6ohzPaKICIa4iBrRGJezaZJ_IpVMFp7Z-SPRgX9ijpbe2ZuZHsNGpCQAiS1YDYTbl4bMCTlOmKdvhBTNkFdHq3EmvvBwCCvjvFLZ-PrmomEjoVo3Dg7tvepu2"]
,null,null,null,"pdf"]
,"","",2]
);</script><div class="ndfHFb-c4YZDc ndfHFb-c4YZDc-AHmuwe-Hr88gd-OWB6Me ndfHFb-c4YZDc-vyDMJf-aZ2wEe ndfHFb-c4YZDc-i5oIFb ndfHFb-c4YZDc-TSZdd" aria-label="Showing viewer." tabindex="0"><div class="ndfHFb-c4YZDc-bnBfGc ndfHFb-c4YZDc-zTETae" tabindex="0" aria-label="Displaying AlphaGoNaturePaper.pdf."></div><div class="ndfHFb-c4YZDc-K9a4Re" style="bottom: 0px;"><div class="ndfHFb-c4YZDc-E7ORLb-LgbsSe ndfHFb-c4YZDc-LgbsSe-OWB6Me ndfHFb-c4YZDc-LgbsSe" role="button" style="-moz-user-select: none; left: 12px; display: none; opacity: 1;" aria-disabled="true" data-tooltip-unhoverable="true" data-tooltip-delay="500" data-tooltip-class="ndfHFb-c4YZDc-tk3N6e-suEOdc" data-tooltip-align="r,c" data-tooltip-offset="-6"><div class="ndfHFb-c4YZDc-DH6Rkf-AHe6Kc"><div class="ndfHFb-c4YZDc-Bz112c ndfHFb-c4YZDc-DH6Rkf-Bz112c"></div></div></div><div class="ndfHFb-c4YZDc-tJiF1e-LgbsSe ndfHFb-c4YZDc-LgbsSe-OWB6Me ndfHFb-c4YZDc-LgbsSe" role="button" style="-moz-user-select: none; right: 12px; display: none; opacity: 1;" aria-disabled="true" data-tooltip-unhoverable="true" data-tooltip-delay="500" data-tooltip-class="ndfHFb-c4YZDc-tk3N6e-suEOdc" data-tooltip-align="l,c" data-tooltip-offset="-6"><div class="ndfHFb-c4YZDc-DH6Rkf-AHe6Kc"><div class="ndfHFb-c4YZDc-Bz112c ndfHFb-c4YZDc-DH6Rkf-Bz112c"></div></div></div><div class="ndfHFb-c4YZDc-q77wGc" style="opacity: 1;"><div class="ndfHFb-c4YZDc-DARUcf-NnAfwf-i5oIFb" style="" aria-label="Page 1 of 20"><div class="ndfHFb-c4YZDc-DARUcf-NnAfwf-tJHJj">Page</div><div class="ndfHFb-c4YZDc-DARUcf-NnAfwf-cQYSPc">1</div><span class="ndfHFb-c4YZDc-DARUcf-NnAfwf-hgDUwe">/</span><div class="ndfHFb-c4YZDc-DARUcf-NnAfwf-j4LONd">20</div></div><div class="ndfHFb-c4YZDc-nJjxad-nK2kYb-i5oIFb" style=""><div class="ndfHFb-c4YZDc-to915-LgbsSe ndfHFb-c4YZDc-nJjxad-m9bMae-LgbsSe VIpgJd-TzA9Ye-eEGnhe ndfHFb-c4YZDc-LgbsSe ndfHFb-c4YZDc-LgbsSe-OWB6Me" role="button" style="-moz-user-select: none;" data-tooltip-unhoverable="true" data-tooltip-delay="500" data-tooltip-class="ndfHFb-c4YZDc-tk3N6e-suEOdc" data-tooltip-align="b,c" data-tooltip-offset="-6" aria-label="Zoom out" data-tooltip="Zoom out" aria-disabled="true"><div class="ndfHFb-c4YZDc-Bz112c"></div></div><div class="ndfHFb-c4YZDc-LgbsSe ndfHFb-c4YZDc-to915-LgbsSe ndfHFb-c4YZDc-nJjxad-hj4D6d-LgbsSe VIpgJd-TzA9Ye-eEGnhe" role="button" style="-moz-user-select: none;" tabindex="0" data-tooltip-unhoverable="true" data-tooltip-delay="500" data-tooltip-class="ndfHFb-c4YZDc-tk3N6e-suEOdc" data-tooltip-align="b,c" data-tooltip-offset="-6" aria-label="Fit to width" data-tooltip="Fit to width"><div class="ndfHFb-c4YZDc-Bz112c"></div></div><div class="ndfHFb-c4YZDc-LgbsSe ndfHFb-c4YZDc-to915-LgbsSe ndfHFb-c4YZDc-nJjxad-bEDTcc-LgbsSe VIpgJd-TzA9Ye-eEGnhe" role="button" style="-moz-user-select: none;" tabindex="0" data-tooltip-unhoverable="true" data-tooltip-delay="500" data-tooltip-class="ndfHFb-c4YZDc-tk3N6e-suEOdc" data-tooltip-align="b,c" data-tooltip-offset="-6" aria-label="Zoom in" data-tooltip="Zoom in"><div class="ndfHFb-c4YZDc-Bz112c"></div></div></div><div class="ndfHFb-c4YZDc-LzGo7c" style="display: none;"></div></div><div class="ndfHFb-c4YZDc-K9a4Re-nKQ6qf ndfHFb-c4YZDc-TvD9Pc-qnnXGd" role="main" style=""><div class="ndfHFb-c4YZDc-EglORb-ge6pde ndfHFb-c4YZDc-K9a4Re-ge6pde-Ne3sFf" role="status" tabindex="-1" aria-label="Loading" style="display: none;"><div class="ndfHFb-c4YZDc-EglORb-ge6pde-RJLb9c ndfHFb-c4YZDc-AHmuwe-wcotoc-zTETae"><div class="ndfHFb-aZ2wEe" dir="ltr"><div class="ndfHFb-vyDMJf-aZ2wEe auswjd"><div class="aZ2wEe-pbTTYe aZ2wEe-v3pZbf"><div class="aZ2wEe-LkdAo-e9ayKc aZ2wEe-LK5yu"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div><div class="aZ2wEe-pehrl-TpMipd"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div><div class="aZ2wEe-LkdAo-e9ayKc aZ2wEe-qwU8Me"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div></div><div class="aZ2wEe-pbTTYe aZ2wEe-oq6NAc"><div class="aZ2wEe-LkdAo-e9ayKc aZ2wEe-LK5yu"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div><div class="aZ2wEe-pehrl-TpMipd"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div><div class="aZ2wEe-LkdAo-e9ayKc aZ2wEe-qwU8Me"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div></div><div class="aZ2wEe-pbTTYe aZ2wEe-gS7Ybc"><div class="aZ2wEe-LkdAo-e9ayKc aZ2wEe-LK5yu"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div><div class="aZ2wEe-pehrl-TpMipd"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div><div class="aZ2wEe-LkdAo-e9ayKc aZ2wEe-qwU8Me"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div></div><div class="aZ2wEe-pbTTYe aZ2wEe-nllRtd"><div class="aZ2wEe-LkdAo-e9ayKc aZ2wEe-LK5yu"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div><div class="aZ2wEe-pehrl-TpMipd"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div><div class="aZ2wEe-LkdAo-e9ayKc aZ2wEe-qwU8Me"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div></div></div></div></div><span class="ndfHFb-c4YZDc-EglORb-ge6pde-fmcmS ndfHFb-c4YZDc-AHmuwe-wcotoc-zTETae" aria-hidden="true">Loading…</span></div><div style="display:none" id="drive-active-item-info">{"id":
 
"\/viewerng\/upload?ds\x3dAON1mFzHiMu5-TzCgoXq4Rrq7dhVYeh_La8L-E1ES8tuJmILl6mlC7LGfAOOiNSAyn-dGmjvrRAWGy52Rbxgn9wU89_8QuoqeQAGsLVDqrS6CudS_4Fa2kRkQddCHMAziBZPCkhrKQ7Gy9cVwj3ANxUM559V6fIIrNBQgXQAneYFs5N6VI166m7BKahQE-ihwmqpLfifUUVLQKwnPIZ0YSC-J1lxpQ4fpMcNCnCmX20DcR_TNL4SqMZF1cEb9h6CWggZhU4Ph2hT9UzBQolU4qlUj-L1EVzKPX47xUStxG61f2vhS85TohU%3D\x26ck\x3dlantern\x26authuser\x26p\x3dproj",
 "title": "AlphaGoNaturePaper.pdf", "mimeType": "application\/pdf"}</div><div class="ndfHFb-c4YZDc-cYSp0e ndfHFb-c4YZDc-oKVyEf" style=""><textarea class="ndfHFb-c4YZDc-cYSp0e-B7I4Od" aria-hidden="true" tabindex="-1"></textarea><div class="ndfHFb-c4YZDc-cYSp0e-s2gQvd ndfHFb-c4YZDc-s2gQvd" tabindex="-1" style="margin-left: 12px;"><div class="ndfHFb-c4YZDc-cYSp0e-Oz6c3e ndfHFb-c4YZDc-cYSp0e-DARUcf-gSKZZ ndfHFb-c4YZDc-neVct-RCfa3e" role="document" tabindex="0" style="margin-top: 56px; margin-bottom: 56px; width: 800px; left: 354.5px;"><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf" style="padding-bottom: 131.375%;"><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-PLDbbf"><a href="http://www.nature.com/doifinder/10.1038/nature16961" target="_blank" class="ndfHFb-c4YZDc-cYSp0e-DARUcf-hSRGPd" tabindex="0" role="link" aria-label="http://www.nature.com/doifinder/10.1038/nature16961" data-saferedirecturl="https://www.google.com/url?q=http://www.nature.com/doifinder/10.1038/nature16961&amp;ust=1552838640000000&amp;usg=AFQjCNH6uOus9sD5Q64rHg2eDUROedH7ZQ&amp;hl=en-US" rel="noreferrer" style="left: 80%; top: 8.05627%; width: 13.1092%; height: 1.53453%;"></a></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-bN97Pc-haAclf"><h2 class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-tJHJj" tabindex="0">Page 1 of 20</h2><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 5.71429%; top: 97.0588%; width: 31.9328%; height: 1.1509%;">484 | NATURE | VOL 529 | 28 JANUARY 2016
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 4.4757%; width: 25.3782%; height: 3.96419%;">ARTICLE
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 77.8151%; top: 8.31202%; width: 15.2941%; height: 1.02302%;">doi:10.1038/nature16961
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 12.4041%; width: 77.3109%; height: 4.85934%;">Mastering the game of Go with deep
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 16.2404%; width: 68.4034%; height: 3.96419%;">neural networks and tree search
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 21.0997%; width: 9.07563%; height: 1.27877%;">David Silver1
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 14.6218%; top: 20.844%; width: 9.41177%; height: 1.79028%;">*, Aja Huang1
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 23.6975%; top: 20.844%; width: 14.2857%; height: 1.79028%;">*, Chris J. Maddison1
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 37.6471%; top: 20.844%; width: 9.91597%; height: 1.79028%;">, Arthur Guez1
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 47.2269%; top: 20.844%; width: 10.2521%; height: 1.79028%;">, Laurent Sifre1
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 57.1429%; top: 20.844%; width: 19.1597%; height: 1.79028%;">, George van den Driessche1
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 75.9664%; top: 20.844%; width: 1.17647%; height: 1.79028%;">,
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 22.3785%; width: 14.2857%; height: 1.40665%;">Julian Schrittwieser1
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 20%; top: 22.2506%; width: 14.958%; height: 1.79028%;">, Ioannis Antonoglou1
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 34.6219%; top: 22.2506%; width: 16.4706%; height: 1.6624%;">, Veda Panneershelvam1
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.7563%; top: 22.2506%; width: 10.5882%; height: 1.6624%;">, Marc Lanctot1
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 61.0084%; top: 22.2506%; width: 13.1092%; height: 1.6624%;">, Sander Dieleman1
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 73.7815%; top: 22.2506%; width: 12.2689%; height: 1.6624%;">, Dominik Grewe1
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 85.7143%; top: 22.2506%; width: 1.34454%; height: 1.6624%;">,
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 23.7852%; width: 8.57143%; height: 1.27877%;">John Nham2
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 14.2857%; top: 23.5294%; width: 13.4454%; height: 1.79028%;">, Nal Kalchbrenner1
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 27.395%; top: 23.5294%; width: 11.2605%; height: 1.79028%;">, Ilya Sutskever2
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 38.3193%; top: 23.5294%; width: 13.2773%; height: 1.79028%;">, Timothy Lillicrap1
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 23.5294%; width: 12.9412%; height: 1.79028%;">, Madeleine Leach1
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 63.8655%; top: 23.5294%; width: 14.7899%; height: 1.79028%;">, Koray Kavukcuoglu1
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 78.3193%; top: 23.5294%; width: 1.34454%; height: 1.79028%;">,
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 25.0639%; width: 10.2521%; height: 1.6624%;">Thore Graepel1
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 15.9664%; top: 24.9361%; width: 13.1092%; height: 1.53453%;">&amp; Demis Hassabis1
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 46.1637%; width: 40.8403%; height: 1.91816%;">All games of perfect information have an optimal value function, v*
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 46.5546%; top: 46.1637%; width: 2.68908%; height: 1.79028%;">(s),
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 5.88235%; top: 47.5703%; width: 43.3613%; height: 1.91816%;">which determines the outcome of the game, from every board position
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 48.8491%; width: 43.1933%; height: 1.91816%;">or state s, under perfect play by all players. These games may be solved
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 5.88235%; top: 50.2558%; width: 43.3613%; height: 1.91816%;">by recursively computing the optimal value function in a search tree
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 51.5345%; width: 17.9832%; height: 1.91816%;">containing approximately bd
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 23.5294%; top: 51.5345%; width: 25.7143%; height: 1.91816%;">possible sequences of moves, where b is
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 52.9412%; width: 43.1933%; height: 1.91816%;">the game’s breadth (number of legal moves per position) and d is its
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 54.2199%; width: 40.1681%; height: 1.91816%;">depth (game length). In large games, such as chess (b≈35, d≈80)1
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 45.7143%; top: 54.2199%; width: 3.52941%; height: 1.6624%;">and
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 55.6266%; width: 20%; height: 1.91816%;">especially Go (b≈250, d≈150)1
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 25.7143%; top: 55.6266%; width: 20.3361%; height: 1.6624%;">, exhaustive search is infeasible2,3
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 45.7143%; top: 55.6266%; width: 3.52941%; height: 1.6624%;">, but
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 56.9054%; width: 43.1933%; height: 1.91816%;">the effective search space can be reduced by two general principles.
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 58.312%; width: 43.1933%; height: 1.91816%;">First, the depth of the search may be reduced by position evaluation:
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 59.5908%; width: 42.8571%; height: 1.91816%;">truncating the search tree at state s and replacing the subtree below s
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 5.88235%; top: 60.9974%; width: 25.7143%; height: 1.91816%;">by an approximate value function v(s)≈v*
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 31.2605%; top: 60.9974%; width: 17.9832%; height: 1.79028%;">(s) that predicts the outcome
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 62.2762%; width: 43.1933%; height: 1.91816%;">from state s. This approach has led to superhuman performance in
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 63.9386%; width: 4.03361%; height: 1.27877%;">chess4
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 9.57983%; top: 63.6829%; width: 6.72269%; height: 1.6624%;">, checkers5
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 15.7983%; top: 63.6829%; width: 8.06723%; height: 1.53453%;">and othello6
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 23.3613%; top: 63.6829%; width: 25.8824%; height: 1.6624%;">, but it was believed to be intractable in Go
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 64.9616%; width: 21.6807%; height: 1.91816%;">due to the complexity of the game7
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 27.395%; top: 64.9616%; width: 21.8487%; height: 1.79028%;">. Second, the breadth of the search
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 66.3683%; width: 43.1933%; height: 3.19693%;">may be reduced by sampling actions from a policy p(a|s) that is a prob-
ability distribution over possible moves a in position s. For example,
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 69.0537%; width: 13.9496%; height: 1.53453%;">Monte Carlo rollouts8
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 19.6639%; top: 69.0537%; width: 29.5798%; height: 1.91816%;">search to maximum depth without branching
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 70.3325%; width: 43.1933%; height: 1.91816%;">at all, by sampling long sequences of actions for both players from a
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 71.7391%; width: 43.1933%; height: 1.91816%;">policy p. Averaging over such rollouts can provide an effective position
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 73.0179%; width: 40.1681%; height: 1.91816%;">evaluation, achieving superhuman performance in backgammon8
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 45.7143%; top: 73.0179%; width: 3.52941%; height: 1.6624%;">and
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 74.6803%; width: 6.05042%; height: 1.27877%;">Scrabble9
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 11.7647%; top: 74.4246%; width: 23.3613%; height: 1.91816%;">, and weak amateur level play in Go10.
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 7.39496%; top: 75.7033%; width: 41.8487%; height: 1.79028%;">Monte Carlo tree search (MCTS)11,12 uses Monte Carlo rollouts
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 5.88235%; top: 77.11%; width: 43.3613%; height: 3.19693%;">to estimate the value of each state in a search tree. As more simu-
lations are executed, the search tree grows larger and the relevant
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 5.88235%; top: 79.7954%; width: 43.3613%; height: 1.91816%;">values become more accurate. The policy used to select actions during
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 81.0742%; width: 43.1933%; height: 1.91816%;">search is also improved over time, by selecting children with higher
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 5.88235%; top: 82.4808%; width: 43.3613%; height: 1.91816%;">values. Asymptotically, this policy converges to optimal play, and the
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 83.7596%; width: 43.1933%; height: 1.91816%;">evaluations converge to the optimal value function12. The strongest
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 85.1662%; width: 43.1933%; height: 1.91816%;">current Go programs are based on MCTS, enhanced by policies that
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 86.445%; width: 43.1933%; height: 1.91816%;">are trained to predict human expert moves13. These policies are used
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 87.8517%; width: 43.1933%; height: 1.91816%;">to narrow the search to a beam of high-probability actions, and to
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 89.1304%; width: 43.1933%; height: 1.91816%;">sample actions during rollouts. This approach has achieved strong
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 90.5371%; width: 43.1933%; height: 1.91816%;">amateur play13–15. However, prior work has been limited to shallow
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 46.1637%; width: 43.1933%; height: 1.91816%;">policies13–15 or value functions16 based on a linear combination of
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 47.5703%; width: 9.41177%; height: 1.79028%;">input features.
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 48.8491%; width: 43.1933%; height: 4.60358%;">Recently, deep convolutional neural networks have achieved unprec-
edented performance in visual domains: for example, image classifica-
tion17, face recognition18, and playing Atari games19. They use many
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 52.9412%; width: 43.1933%; height: 1.91816%;">layers of neurons, each arranged in overlapping tiles, to construct
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 54.2199%; width: 43.1933%; height: 1.91816%;">increasingly abstract, localized representations of an image20. We
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 55.6266%; width: 43.1933%; height: 1.91816%;">employ a similar architecture for the game of Go. We pass in the board
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 56.9054%; width: 43.1933%; height: 1.91816%;">position as a 19×19 image and use convolutional layers to construct a
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 58.312%; width: 43.1933%; height: 1.79028%;">representation of the position. We use these neural networks to reduce
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 59.5908%; width: 43.1933%; height: 1.91816%;">the effective depth and breadth of the search tree: evaluating positions
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 60.9974%; width: 42.0168%; height: 1.91816%;">using a value network, and sampling actions using a policy network.
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.7647%; top: 62.2762%; width: 41.6807%; height: 1.91816%;">We train the neural networks using a pipeline consisting of several
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 63.6829%; width: 43.1933%; height: 1.91816%;">stages of machine learning (Fig. 1). We begin by training a supervised
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 64.9616%; width: 43.1933%; height: 1.91816%;">learning (SL) policy network pσ directly from expert human moves.
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 66.3683%; width: 43.1933%; height: 1.91816%;">This provides fast, efficient learning updates with immediate feedback
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 67.6471%; width: 43.1933%; height: 1.91816%;">and high-quality gradients. Similar to prior work13,15, we also train a
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 69.0537%; width: 43.1933%; height: 1.91816%;">fast policy pπ that can rapidly sample actions during rollouts. Next, we
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 70.3325%; width: 43.1933%; height: 2.04604%;">train a reinforcement learning (RL) policy network pρ that improves
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 71.7391%; width: 43.1933%; height: 3.19693%;">the SL policy network by optimizing the final outcome of games of self-
play. This adjusts the policy towards the correct goal of winning games,
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 74.4246%; width: 43.1933%; height: 1.91816%;">rather than maximizing predictive accuracy. Finally, we train a value
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 75.7033%; width: 43.1933%; height: 1.91816%;">network vθ that predicts the winner of games played by the RL policy
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 77.11%; width: 43.1933%; height: 1.91816%;">network against itself. Our program AlphaGo efficiently combines the
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 78.3888%; width: 24.2017%; height: 1.91816%;">policy and value networks with MCTS.
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 81.0742%; width: 30.084%; height: 1.91816%;">Supervised learning of policy networks
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 82.4808%; width: 43.1933%; height: 1.91816%;">For the first stage of the training pipeline, we build on prior work
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 83.7596%; width: 43.1933%; height: 1.91816%;">on predicting expert moves in the game of Go using supervised
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 85.1662%; width: 43.1933%; height: 4.60358%;">learning13,21–24. The SL policy network pσ(a| s) alternates between con-
volutional layers with weights σ, and rectifier nonlinearities. A final soft-
max layer outputs a probability distribution over all legal moves a. The
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 89.1304%; width: 43.1933%; height: 1.91816%;">input s to the policy network is a simple representation of the board state
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.4202%; top: 90.5371%; width: 43.0252%; height: 1.91816%;">(see Extended Data Table 2). The policy network is trained on randomly
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 7.39496%; top: 30.3069%; width: 84.7059%; height: 1.91816%;">The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 7.39496%; top: 31.7136%; width: 84.7059%; height: 1.79028%;">enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 7.39496%; top: 32.9923%; width: 84.7059%; height: 1.91816%;">to computer Go that uses ‘value networks’ to evaluate board positions and ‘policy networks’ to select moves. These deep
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 7.39496%; top: 34.399%; width: 84.7059%; height: 1.79028%;">neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 7.39496%; top: 35.6778%; width: 84.7059%; height: 3.19693%;">learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-
of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 7.39496%; top: 38.3632%; width: 84.7059%; height: 1.91816%;">new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm,
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 7.39496%; top: 39.7698%; width: 84.7059%; height: 1.79028%;">our program AlphaGo achieved a 99.8% winning rate against other Go programs, and defeated the human European Go
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 7.39496%; top: 41.0486%; width: 84.7059%; height: 1.91816%;">champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 7.39496%; top: 42.4552%; width: 53.9496%; height: 1.79028%;">full-sized game of Go, a feat previously thought to be at least a decade away.
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 93.4783%; width: 63.6975%; height: 1.27877%;">1Google
 DeepMind, 5 New Street Square, London EC4A 3TW, UK. 2Google, 1600 
Amphitheatre Parkway, Mountain View, California 94043, USA.
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 5.88235%; top: 94.5013%; width: 21.8487%; height: 1.27877%;">*These authors contributed equally to this work.
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 35.4622%; top: 98.0818%; width: 27.7311%; height: 1.40665%;">© 2016 Macmillan Publishers Limited. All rights reserved
</p></div><div class="ndfHFb-c4YZDc-cYSp0e-wxLEad-sn54Q" style="display: none;"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-gvZm2b"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-cYSp0e-oYxtQd-gvZm2b"></div><img src="blob:https://drive.google.com/8e7204de-676d-4023-82ca-1244418f2a8c" class="ndfHFb-c4YZDc-cYSp0e-DARUcf-RJLb9c" alt="Page 1 of 20" aria-hidden="true"></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf" style="padding-bottom: 131.375%;"><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-PLDbbf"></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-bN97Pc-haAclf"><h2 class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-tJHJj" tabindex="0">Page 2 of 20</h2><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 62.3529%; top: 97.0588%; width: 31.9328%; height: 1.1509%;">28 JANUARY 2016 | VOL 529 | NATURE | 485
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 79.1597%; top: 3.06905%; width: 14.2857%; height: 1.53453%;">ARTICLE RESEARCH
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 41.0486%; width: 43.1933%; height: 1.91816%;">sampled state-action pairs (s, a), using stochastic gradient ascent to
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 42.4552%; width: 39.3277%; height: 1.53453%;">maximize the likelihood of the human move a selected in state s
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 22.1849%; top: 45.0128%; width: 12.1008%; height: 3.06905%;">∆σ σ ∝ ∂ ( | )
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 29.0756%; top: 46.9309%; width: 1.34454%; height: 1.27877%;">∂
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 27.2269%; top: 45.0128%; width: 6.55462%; height: 1.6624%;">σ log p a s
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 8.40336%; top: 48.5934%; width: 41.8487%; height: 1.91816%;">We trained a 13-layer policy network, which we call the SL policy
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 50%; width: 43.1933%; height: 3.19693%;">network, from 30 million positions from the KGS Go Server. The net-
work predicted expert moves on a held out test set with an accuracy of
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 52.6854%; width: 43.1933%; height: 3.19693%;">57.0% using all input features, and 55.7% using only raw board posi-
tion and move history as inputs, compared to the state-of-the-art from
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 55.3708%; width: 43.1933%; height: 1.79028%;">other research groups of 44.4% at date of submission24 (full results in
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 56.6496%; width: 43.1933%; height: 1.91816%;">Extended Data Table 3). Small improvements in accuracy led to large
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 58.0563%; width: 43.1933%; height: 1.79028%;">improvements in playing strength (Fig. 2a); larger networks achieve
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 59.335%; width: 43.1933%; height: 1.91816%;">better accuracy but are slower to evaluate during search. We also
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 60.7417%; width: 43.1933%; height: 1.79028%;">trained a faster but less accurate rollout policy pπ(a|s), using a linear
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 62.0205%; width: 43.1933%; height: 1.91816%;">softmax of small pattern features (see Extended Data Table 4) with
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 63.4271%; width: 43.1933%; height: 1.79028%;">weights π; this achieved an accuracy of 24.2%, using just 2μs to select
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 64.7059%; width: 30.9244%; height: 1.91816%;">an action, rather than 3ms for the policy network.
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 67.3913%; width: 32.7731%; height: 1.91816%;">Reinforcement learning of policy networks
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 68.798%; width: 43.1933%; height: 1.79028%;">The second stage of the training pipeline aims at improving the policy
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 70.0767%; width: 43.1933%; height: 1.91816%;">network by policy gradient reinforcement learning (RL)25,26. The RL
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 71.4834%; width: 43.1933%; height: 1.91816%;">policy network pρ is identical in structure to the SL policy network,
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 41.0486%; width: 43.1933%; height: 1.91816%;">and its weights ρ are initialized to the same values, ρ=σ. We play
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 42.4552%; width: 43.1933%; height: 1.91816%;">games between the current policy network pρ and a randomly selected
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 43.734%; width: 43.1933%; height: 1.91816%;">previous iteration of the policy network. Randomizing from a pool
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 45.1407%; width: 43.1933%; height: 1.79028%;">of opponents in this way stabilizes training by preventing overfitting
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 46.4194%; width: 43.1933%; height: 1.91816%;">to the current policy. We use a reward function r(s) that is zero for all
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 47.8261%; width: 43.1933%; height: 3.19693%;">non-terminal time steps t&lt;T. The outcome zt=±r(sT) is the termi-
nal reward at the end of the game from the perspective of the current
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 50.5115%; width: 43.1933%; height: 1.79028%;">player at time step t: +1 for winning and −1 for losing. Weights are
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 51.7903%; width: 43.1933%; height: 1.91816%;">then updated at each time step t by stochastic gradient ascent in the
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 53.1969%; width: 28.2353%; height: 1.79028%;">direction that maximizes expected outcome25
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 65.3782%; top: 57.1611%; width: 2.52101%; height: 1.53453%;">∆ρ
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 67.7311%; top: 56.1381%; width: 10.5882%; height: 3.45269%;">ρ ∝ ∂ ( | )
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 72.7731%; top: 58.1841%; width: 1.34454%; height: 1.27877%;">∂
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 70.4202%; top: 56.1381%; width: 8.90756%; height: 2.30179%;">ρp a s z log t t
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 78.9916%; top: 57.8005%; width: 0.840336%; height: 0.767264%;">t
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 52.605%; top: 60.6138%; width: 41.8487%; height: 1.91816%;">We evaluated the performance of the RL policy network in game
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 62.0205%; width: 43.1933%; height: 2.17391%;">play, sampling each move ~ (⋅| ) ρ at t p s from its output probability
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 63.2992%; width: 43.1933%; height: 1.91816%;">distribution over actions. When played head-to-head, the RL policy
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 64.7059%; width: 43.1933%; height: 1.79028%;">network won more than 80% of games against the SL policy network.
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 65.9847%; width: 43.1933%; height: 1.91816%;">We also tested against the strongest open-source Go program, Pachi14,
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 67.3913%; width: 42.8571%; height: 1.79028%;">a sophisticated Monte Carlo search program, ranked at 2 amateur dan
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 68.6701%; width: 43.1933%; height: 1.91816%;">on KGS, that executes 100,000 simulations per move. Using no search
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 70.0767%; width: 43.1933%; height: 3.19693%;">at all, the RL policy network won 85% of games against Pachi. In com-
parison, the previous state-of-the-art, based only on supervised
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 28.9003%; width: 41.5126%; height: 1.6624%;">Figure 1 | Neural network training pipeline and architecture. a, A fast
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 30.0512%; width: 38.9916%; height: 1.79028%;">rollout policy pπ and supervised learning (SL) policy network pσ are
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 31.3299%; width: 37.1429%; height: 1.6624%;">trained to predict human expert moves in a data set of positions.
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 32.4808%; width: 41.0084%; height: 1.79028%;">A reinforcement learning (RL) policy network pρ is initialized to the SL
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 33.7596%; width: 38.9916%; height: 1.6624%;">policy network, and is then improved by policy gradient learning to
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 34.9105%; width: 40.5042%; height: 1.79028%;">maximize the outcome (that is, winning more games) against previous
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 36.1893%; width: 40%; height: 1.6624%;">versions of the policy network. A new data set is generated by playing
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 37.3402%; width: 41.8487%; height: 1.79028%;">games of self-play with the RL policy network. Finally, a value network vθ
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 38.6189%; width: 42.0168%; height: 1.6624%;">is trained by regression to predict the expected outcome (that is, whether
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 28.9003%; width: 36.6387%; height: 1.6624%;">the current player wins) in positions from the self-play data set.
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 30.0512%; width: 40.6723%; height: 1.79028%;">b, Schematic representation of the neural network architecture used in
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 31.3299%; width: 42.521%; height: 1.6624%;">AlphaGo. The policy network takes a representation of the board position
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 32.4808%; width: 42.521%; height: 1.79028%;">s as its input, passes it through many convolutional layers with parameters
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 33.7596%; width: 42.3529%; height: 1.6624%;">σ (SL policy network) or ρ (RL policy network), and outputs a probability
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 34.9105%; width: 17.3109%; height: 2.04604%;">distribution ( | ) σp a s or ( | ) ρ
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 64.2017%; top: 34.9105%; width: 25.2101%; height: 1.79028%;">p a s over legal moves a, represented by a
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 36.1893%; width: 41.0084%; height: 1.6624%;">probability map over the board. The value network similarly uses many
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 37.3402%; width: 40.8403%; height: 1.79028%;">convolutional layers with parameters θ, but outputs a scalar value vθ(s′)
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 38.6189%; width: 28.2353%; height: 1.6624%;">that predicts the expected outcome in position s′.
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 48.7395%; top: 19.9488%; width: 3.52941%; height: 3.83632%;">Regression
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 21.0084%; top: 19.1816%; width: 4.03361%; height: 4.4757%;">Classication
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 14.1176%; top: 19.3095%; width: 4.03361%; height: 4.60358%;">Classication
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 41.8487%; top: 19.5652%; width: 3.02521%; height: 3.32481%;">Self Play
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 29.4118%; top: 15.601%; width: 7.05882%; height: 1.27877%;">Policy gradient
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 11.0924%; top: 6.77749%; width: 52.605%; height: 1.1509%;">a b
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 12.9412%; top: 27.4936%; width: 39.4958%; height: 1.40665%;">Human expert positions Self-play positions
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 59.1597%; top: 10.9974%; width: 1.68067%; height: 16.1125%;">Neural network Data
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 11.5966%; top: 8.18414%; width: 7.56303%; height: 1.53453%;">Rollout policy
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 14.2857%; top: 11.3811%; width: 70.7563%; height: 1.6624%;">pS pV pVU (a⎪s) QT p (s′) U QT
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 21.0084%; top: 8.18414%; width: 66.3866%; height: 1.53453%;">SL policy network RL policy network Value network Policy network Value network
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 71.7647%; top: 26.5985%; width: 16.1345%; height: 1.1509%;">s s′
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 86.8286%; width: 37.3109%; height: 1.79028%;">Figure 2 | Strength and accuracy of policy and value networks.
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 88.1074%; width: 39.4958%; height: 1.6624%;">a, Plot showing the playing strength of policy networks as a function
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 89.2583%; width: 40.1681%; height: 1.79028%;">of their training accuracy. Policy networks with 128, 192, 256 and 384
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 90.5371%; width: 42.521%; height: 1.6624%;">convolutional filters per layer were evaluated periodically during training;
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 91.688%; width: 40.1681%; height: 1.79028%;">the plot shows the winning rate of AlphaGo using that policy network
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 92.9668%; width: 38.9916%; height: 1.6624%;">against the match version of AlphaGo. b, Comparison of evaluation
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.89076%; top: 94.1176%; width: 41.5126%; height: 1.79028%;">accuracy between the value network and rollouts with different policies.
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 86.8286%; width: 40.8403%; height: 1.79028%;">Positions and outcomes were sampled from human expert games. Each
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 88.1074%; width: 41.0084%; height: 1.6624%;">position was evaluated by a single forward pass of the value network vθ,
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 89.2583%; width: 41.5126%; height: 1.79028%;">or by the mean outcome of 100 rollouts, played out using either uniform
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 90.5371%; width: 40.3361%; height: 1.6624%;">random rollouts, the fast rollout policy pπ, the SL policy network pσ or
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 91.688%; width: 42.0168%; height: 1.79028%;">the RL policy network pρ. The mean squared error between the predicted
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.2605%; top: 92.9668%; width: 42.6891%; height: 1.6624%;">value and the actual game outcome is plotted against the stage of the game
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.4286%; top: 94.1176%; width: 32.7731%; height: 1.79028%;">(how many moves had been played in the given position).
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 58.1513%; top: 84.9105%; width: 23.1933%; height: 0.895141%;">15 45 75 105 135 165 195 225 255 &gt;285
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 66.0504%; top: 85.6778%; width: 5.54622%; height: 1.02302%;">Move number
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 55.2941%; top: 84.2711%; width: 2.01681%; height: 0.767264%;">0.10
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 55.2941%; top: 83.2481%; width: 2.01681%; height: 0.767264%;">0.15
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 55.2941%; top: 82.0972%; width: 2.01681%; height: 0.895141%;">0.20
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 55.2941%; top: 81.0742%; width: 2.01681%; height: 0.895141%;">0.25
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 55.2941%; top: 80.0512%; width: 2.01681%; height: 0.895141%;">0.30
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 55.2941%; top: 79.0281%; width: 2.01681%; height: 0.895141%;">0.35
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 55.2941%; top: 78.0051%; width: 2.01681%; height: 0.895141%;">0.40
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 55.2941%; top: 76.9821%; width: 2.01681%; height: 0.767264%;">0.45
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 55.2941%; top: 75.9591%; width: 2.01681%; height: 0.767264%;">0.50
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 52.1008%; top: 77.6215%; width: 1.51261%; height: 6.01023%;">Mean squared error
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 53.1092%; top: 78.0051%; width: 1.51261%; height: 5.24297%;">on expert games
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 60%; top: 78.9003%; width: 6.38656%; height: 1.02302%;">Uniform random
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 60%; top: 79.6675%; width: 5.21008%; height: 1.1509%;">rollout policy
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 60%; top: 80.5627%; width: 7.05882%; height: 1.1509%;">Fast rollout policy
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 59.8319%; top: 81.4578%; width: 5.88235%; height: 1.02302%;">Value network
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 59.8319%; top: 82.3529%; width: 7.22689%; height: 1.1509%;">SL policy network
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 60%; top: 83.2481%; width: 7.05882%; height: 1.1509%;">RL policy network
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 22.0168%; top: 84.9105%; width: 27.2269%; height: 0.895141%;">50 51 52 53 54 55 56 57 58 59
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 27.8992%; top: 85.6778%; width: 14.7899%; height: 1.1509%;">Training accuracy on KGS dataset (%)
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 21.5126%; top: 84.2711%; width: 1.0084%; height: 0.895141%;">0
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 21.1765%; top: 82.9923%; width: 1.34454%; height: 0.895141%;">10
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 21.1765%; top: 81.7136%; width: 1.34454%; height: 0.895141%;">20
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 21.1765%; top: 80.5627%; width: 1.34454%; height: 0.767264%;">30
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 21.1765%; top: 79.2839%; width: 1.34454%; height: 0.767264%;">40
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 21.1765%; top: 78.0051%; width: 1.34454%; height: 0.895141%;">50
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 21.1765%; top: 76.7263%; width: 1.34454%; height: 0.895141%;">60
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 21.1765%; top: 75.4476%; width: 1.34454%; height: 0.895141%;">70
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 24.8739%; top: 75.9591%; width: 4.20168%; height: 1.02302%;">128 lters
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 24.8739%; top: 76.7263%; width: 4.20168%; height: 1.02302%;">192 lters
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 24.8739%; top: 77.4936%; width: 4.20168%; height: 1.02302%;">256 lters
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 24.8739%; top: 78.133%; width: 4.20168%; height: 1.02302%;">384 lters
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 19.4958%; top: 77.11%; width: 1.51261%; height: 6.39386%;">AlphaGo win rate (%)
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 19.6639%; top: 74.0409%; width: 34.1177%; height: 1.1509%;">a b
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 36.8067%; top: 98.0818%; width: 27.7311%; height: 1.40665%;">© 2016 Macmillan Publishers Limited. All rights reserved
</p></div><div class="ndfHFb-c4YZDc-cYSp0e-wxLEad-sn54Q" style="display: none;"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-gvZm2b"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-cYSp0e-oYxtQd-gvZm2b"></div><img src="blob:https://drive.google.com/fe35b747-769f-4912-9244-04c1a51ef449" class="ndfHFb-c4YZDc-cYSp0e-DARUcf-RJLb9c" alt="Page 2 of 20" aria-hidden="true"></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf" style="padding-bottom: 131.375%;"><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-PLDbbf"></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-bN97Pc-haAclf"><h2 class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-tJHJj" tabindex="0">Page 3 of 20</h2><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 5.71429%; top: 97.0588%; width: 31.9328%; height: 1.1509%;">486 | NATURE | VOL 529 | 28 JANUARY 2016
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.55462%; top: 3.06905%; width: 14.2857%; height: 1.53453%;">RESEARCH ARTICLE
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 5.88235%; top: 34.5269%; width: 42.8571%; height: 1.91816%;">learning of convolutional networks, won 11% of games against Pachi23
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 35.9335%; width: 32.2689%; height: 1.79028%;">and 12% against a slightly weaker program, Fuego24.
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 38.2353%; width: 32.1008%; height: 2.04604%;">Reinforcement learning of value networks
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 39.7698%; width: 43.1933%; height: 1.79028%;">The final stage of the training pipeline focuses on position evaluation,
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 41.0486%; width: 18.4874%; height: 1.91816%;">estimating a value function vp
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 41.0486%; width: 42.1849%; height: 3.19693%;">(s) that predicts the outcome from posi-
tion s of games played by using policy p for both players28–30
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 18.1513%; top: 45.3964%; width: 18.4874%; height: 1.53453%;">v s( )= | E[ , z s = ~ s a ... p] p t t t T
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 7.39496%; top: 47.4425%; width: 41.8487%; height: 1.91816%;">Ideally, we would like to know the optimal value function under
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 48.8491%; width: 9.2437%; height: 1.91816%;">perfect play v*
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 14.958%; top: 48.8491%; width: 34.2857%; height: 1.79028%;">(s); in practice, we instead estimate the value function
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 5.88235%; top: 50.7673%; width: 2.18487%; height: 1.02302%;">v ρ
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 5.88235%; top: 50.1279%; width: 43.3613%; height: 4.60358%;">p
 for our strongest policy, using the RL policy network pρ. We approx-
imate the value function using a value network vθ(s) with weights θ, ⁎ v
 s θ( )≈ ( v s ρ ) ≈ v s( ) p . This neural network has a similar 
architecture
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 54.2199%; width: 43.1933%; height: 4.60358%;">to the policy network, but outputs a single prediction instead of a prob-
ability distribution. We train the weights of the value network by regres-
sion on state-outcome pairs (s, z), using stochastic gradient descent to
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 58.1841%; width: 43.1933%; height: 1.91816%;">minimize the mean squared error (MSE) between the predicted value
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 59.5908%; width: 24.3697%; height: 1.91816%;">vθ(s), and the corresponding outcome z
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 19.8319%; top: 63.1714%; width: 2.52101%; height: 1.27877%;">∆θ
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 22.1849%; top: 62.2762%; width: 5.88235%; height: 3.06905%;">θ ∝ ∂ ( )
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 25.042%; top: 62.7877%; width: 9.7479%; height: 2.55754%;">∂ ( − ( )) θ
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 31.7647%; top: 63.555%; width: 0.840336%; height: 1.02302%;">θ
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 24.8739%; top: 62.6598%; width: 8.90756%; height: 1.79028%;">v s z v s
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 66.1125%; width: 43.1933%; height: 3.19693%;">The naive approach of predicting game outcomes from data con-
sisting of complete games leads to overfitting. The problem is that
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 68.798%; width: 43.1933%; height: 1.91816%;">successive positions are strongly correlated, differing by just one stone,
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 5.88235%; top: 70.0767%; width: 43.3613%; height: 1.91816%;">but the regression target is shared for the entire game. When trained
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 71.4834%; width: 43.1933%; height: 1.91816%;">on the KGS data set in this way, the value network memorized the
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 72.7621%; width: 43.1933%; height: 1.91816%;">game outcomes rather than generalizing to new positions, achieving a
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 74.1688%; width: 43.1933%; height: 1.91816%;">minimum MSE of 0.37 on the test set, compared to 0.19 on the training
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 75.4476%; width: 43.1933%; height: 1.91816%;">set. To mitigate this problem, we generated a new self-play data set
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 76.8542%; width: 43.1933%; height: 3.19693%;">consisting of 30 million distinct positions, each sampled from a sepa-
rate game. Each game was played between the RL policy network and
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 79.5396%; width: 43.1933%; height: 1.91816%;">itself until the game terminated. Training on this data set led to MSEs
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 80.8184%; width: 43.1933%; height: 1.91816%;">of 0.226 and 0.234 on the training and test set respectively, indicating
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 82.2251%; width: 43.1933%; height: 1.91816%;">minimal overfitting. Figure 2b shows the position evaluation accuracy
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 83.5038%; width: 43.1933%; height: 1.91816%;">of the value network, compared to Monte Carlo rollouts using the fast
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 84.9105%; width: 43.1933%; height: 1.91816%;">rollout policy pπ; the value function was consistently more accurate.
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 86.1893%; width: 43.1933%; height: 1.91816%;">A single evaluation of vθ(s) also approached the accuracy of Monte
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 87.5959%; width: 43.1933%; height: 1.91816%;">Carlo rollouts using the RL policy network pρ, but using 15,000 times
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 5.88235%; top: 88.8747%; width: 11.2605%; height: 1.91816%;">less computation.
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 91.3044%; width: 31.9328%; height: 1.91816%;">Searching with policy and value networks
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 92.711%; width: 43.1933%; height: 3.32481%;">AlphaGo combines the policy and value networks in an MCTS algo-
rithm (Fig. 3) that selects actions by lookahead search. Each edge
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.4202%; top: 34.5269%; width: 43.0252%; height: 1.79028%;">(s, a) of the search tree stores an action value Q(s, a), visit count N(s, a),
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 35.9335%; width: 43.1933%; height: 1.79028%;">and prior probability P(s, a). The tree is traversed by simulation (that
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 37.2123%; width: 43.1933%; height: 1.91816%;">is, descending the tree in complete games without backup), starting
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 38.6189%; width: 42.8571%; height: 1.79028%;">from the root state. At each time step t of each simulation, an action at
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 39.8977%; width: 14.2857%; height: 1.79028%;">is selected from state st
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 61.8487%; top: 42.8389%; width: 19.6639%; height: 2.42967%;">a Q t = ( argmax ( ) s a, , + ( u s a)) a
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 72.2689%; top: 43.4783%; width: 6.89076%; height: 0.767264%;">t t
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 46.0358%; width: 27.0588%; height: 1.91816%;">so as to maximize action value plus a bonus
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 66.0504%; top: 48.977%; width: 10.5882%; height: 2.42967%;">( )∝ ( )
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 65.042%; top: 49.1049%; width: 12.9412%; height: 3.19693%;">+ ( ) u s a P s a
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 67.0588%; top: 49.7442%; width: 10.4202%; height: 2.30179%;">N s a , ,
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 71.0924%; top: 50.8951%; width: 5.37815%; height: 1.27877%;">1 ,
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 53.1969%; width: 43.1933%; height: 1.79028%;">that is proportional to the prior probability but decays with
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 54.4757%; width: 43.1933%; height: 1.91816%;">repeated visits to encourage exploration. When the traversal reaches a
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 55.8824%; width: 43.1933%; height: 1.79028%;">leaf node sL at step L, the leaf node may be expanded. The leaf position
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 57.1611%; width: 43.1933%; height: 3.19693%;">sL is processed just once by the SL policy network pσ. The output prob-
abilities are stored as prior probabilities P for each legal action a,
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 59.8466%; width: 43.1933%; height: 2.04604%;">( )= ( | ) σ P s a, p a s . The leaf node is evaluated in two very different ways:
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 61.2532%; width: 43.1933%; height: 1.79028%;">first, by the value network vθ(sL); and second, by the outcome zL of a
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 62.532%; width: 43.1933%; height: 1.91816%;">random rollout played out until terminal step T using the fast rollout
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 63.9386%; width: 43.1933%; height: 1.79028%;">policy pπ; these evaluations are combined, using a mixing parameter
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 65.2174%; width: 18.1513%; height: 1.79028%;">λ, into a leaf evaluation V(sL)
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 63.0252%; top: 68.0307%; width: 17.3109%; height: 1.6624%;">V s( )L L = (1− ) λ λ v s θ( )+ zL
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.7647%; top: 70.3325%; width: 41.6807%; height: 1.79028%;">At the end of simulation, the action values and visit counts of all
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 71.7391%; width: 43.1933%; height: 1.91816%;">traversed edges are updated. Each edge accumulates the visit count and
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 73.0179%; width: 37.479%; height: 1.91816%;">mean evaluation of all simulations passing through that edge
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 66.8908%; top: 76.5985%; width: 2.18487%; height: 1.79028%;">∑
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 71.7647%; top: 80.0512%; width: 2.18487%; height: 1.6624%;">∑
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 62.1849%; top: 76.7263%; width: 11.9328%; height: 1.53453%;">( )= ( )
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 61.8487%; top: 80.0512%; width: 20.6723%; height: 2.55754%;">( )= ( ) ( ) ( )
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 67.2269%; top: 78.5166%; width: 1.34454%; height: 0.639386%;">=
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 72.2689%; top: 81.8414%; width: 1.17647%; height: 0.639386%;">=
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 60.8403%; top: 76.8542%; width: 12.7731%; height: 1.1509%;">N s a s a i
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 60.8403%; top: 80.179%; width: 20.5042%; height: 2.04604%;">Q s a N s a s a i V s
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 63.1933%; top: 76.8542%; width: 9.7479%; height: 1.27877%;">, 1 , ,
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 62.8571%; top: 79.4118%; width: 6.89076%; height: 2.04604%;">, 1
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 69.2437%; top: 80.179%; width: 8.57143%; height: 2.17391%;">, 1 , ,
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 66.8908%; top: 78.2609%; width: 0.840336%; height: 0.895141%;">i
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 67.563%; top: 75.9591%; width: 0.840336%; height: 0.767264%;">n
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 71.7647%; top: 81.7136%; width: 0.840336%; height: 0.895141%;">i
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 72.437%; top: 79.2839%; width: 0.840336%; height: 0.767264%;">n
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 81.0084%; top: 80.6905%; width: 1.0084%; height: 0.895141%;">L
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 81.0084%; top: 79.9233%; width: 0.840336%; height: 0.895141%;">i
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 68.2353%; top: 78.2609%; width: 0.840336%; height: 0.895141%;">1
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 73.1092%; top: 81.7136%; width: 0.840336%; height: 0.895141%;">1
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 83.376%; width: 5.71429%; height: 1.91816%;">where sL
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 54.7899%; top: 83.5038%; width: 0.840336%; height: 0.895141%;">i
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 55.4622%; top: 83.376%; width: 37.9832%; height: 1.79028%;">is the leaf node from the ith simulation, and 1(s, a, i) indicates
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 84.6547%; width: 43.1933%; height: 1.91816%;">whether an edge (s, a) was traversed during the ith simulation. Once
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 86.0614%; width: 43.1933%; height: 1.91816%;">the search is complete, the algorithm chooses the most visited move
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 87.3402%; width: 14.4538%; height: 1.91816%;">from the root position.
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 51.7647%; top: 88.7468%; width: 41.6807%; height: 1.91816%;">It is worth noting that the SL policy network pσ performed better in
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 90.0256%; width: 43.1933%; height: 2.04604%;">AlphaGo than the stronger RL policy network pρ, presumably because
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 91.4322%; width: 43.1933%; height: 3.19693%;">humans select a diverse beam of promising moves, whereas RL opti-
mizes for the single best move. However, the value function
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 94.1176%; width: 43.1933%; height: 1.91816%;">v s θ( )≈ ( v s ρ ) p derived from the stronger RL policy network performed
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 25.9591%; width: 38.9916%; height: 1.6624%;">Figure 3 | Monte Carlo tree search in AlphaGo. a, Each simulation
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 5.88235%; top: 27.11%; width: 40.3361%; height: 1.79028%;">traverses the tree by selecting the edge with maximum action value Q,
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 5.88235%; top: 28.3887%; width: 40.1681%; height: 1.6624%;">plus a bonus u(P) that depends on a stored prior probability P for that
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 6.05042%; top: 29.5396%; width: 41.6807%; height: 1.79028%;">edge. b, The leaf node may be expanded; the new node is processed once
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 5.88235%; top: 30.8184%; width: 41.1765%; height: 1.6624%;">by the policy network pσ and the output probabilities are stored as prior
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 5.88235%; top: 31.9693%; width: 42.1849%; height: 1.79028%;">probabilities P for each action. c, At the end of a simulation, the leaf node
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.4202%; top: 25.9591%; width: 39.1597%; height: 1.79028%;">is evaluated in two ways: using the value network vθ; and by running
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.4202%; top: 27.2379%; width: 38.3193%; height: 1.6624%;">a rollout to the end of the game with the fast rollout policy pπ, then
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.4202%; top: 28.3887%; width: 41.6807%; height: 1.79028%;">computing the winner with function r. d, Action values Q are updated to
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 29.6675%; width: 41.5126%; height: 1.6624%;">track the mean value of all evaluations r(·) and vθ(·) in the subtree below
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 30.8184%; width: 6.89076%; height: 1.53453%;">that action.
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 11.2605%; top: 6.77749%; width: 65.042%; height: 1.40665%;">a b Selection Expansion c d Evaluation Backup
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 52.2689%; top: 20.7161%; width: 1.68067%; height: 1.1509%;">pS
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 30.5882%; top: 17.9028%; width: 1.68067%; height: 1.1509%;">pV
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 14.2857%; top: 15.7289%; width: 4.53782%; height: 1.53453%;">Q + u(P)
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 12.1008%; top: 11.3811%; width: 15.6303%; height: 1.6624%;">Q + u Q + u(P) (P)
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 25.2101%; top: 15.8568%; width: 4.70588%; height: 1.40665%;">Q + u(P)
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 32.7731%; top: 11.2532%; width: 5.88235%; height: 1.02302%;">P P
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 35.4622%; top: 15.4731%; width: 5.88235%; height: 1.02302%;">P P
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 70.084%; top: 11.2532%; width: 1.34454%; height: 1.1509%;">Q
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 81.5126%; top: 14.9616%; width: 1.34454%; height: 1.02302%;">Q
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 76.6387%; top: 11.1253%; width: 1.34454%; height: 1.02302%;">Q
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 76.8067%; top: 14.9616%; width: 1.34454%; height: 1.02302%;">Q
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.7563%; top: 23.4015%; width: 30.084%; height: 0.895141%;">r r r r
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 32.1008%; top: 19.5652%; width: 1.34454%; height: 1.02302%;">P
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 20.8403%; top: 16.3683%; width: 2.52101%; height: 0.767264%;">max
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 18.6555%; top: 12.1483%; width: 2.52101%; height: 0.895141%;">max
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 36.6387%; top: 19.6931%; width: 1.17647%; height: 1.02302%;">P
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 50.2521%; top: 17.6471%; width: 1.51261%; height: 1.1509%;">QT
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 64.0336%; top: 13.4271%; width: 1.51261%; height: 1.1509%;">QT
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 69.916%; top: 9.84655%; width: 1.51261%; height: 1.1509%;">QT
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 75.7983%; top: 13.4271%; width: 1.51261%; height: 1.02302%;">QT
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 72.7731%; top: 17.9028%; width: 8.23529%; height: 1.1509%;">QT QT
</p><p class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-eEGnhe" style="left: 35.4622%; top: 98.0818%; width: 27.7311%; height: 1.40665%;">© 2016 Macmillan Publishers Limited. All rights reserved
</p></div><div class="ndfHFb-c4YZDc-cYSp0e-wxLEad-sn54Q" style="display: none;"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-gvZm2b"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-cYSp0e-oYxtQd-gvZm2b"></div><img src="blob:https://drive.google.com/ba186253-0a6e-4041-aadd-466c636b5d43" class="ndfHFb-c4YZDc-cYSp0e-DARUcf-RJLb9c" alt="Page 3 of 20" aria-hidden="true"></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf" style="padding-bottom: 131.375%;"><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-PLDbbf"></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-bN97Pc-haAclf"></div><div class="ndfHFb-c4YZDc-cYSp0e-wxLEad-sn54Q" style="display: none;"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-gvZm2b"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-cYSp0e-oYxtQd-gvZm2b"></div></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf" style="padding-bottom: 131.375%;"><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-PLDbbf"></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-bN97Pc-haAclf"></div><div class="ndfHFb-c4YZDc-cYSp0e-wxLEad-sn54Q" style="display: none;"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-gvZm2b"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-cYSp0e-oYxtQd-gvZm2b"></div></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf" style="padding-bottom: 131.375%;"><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-PLDbbf"></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-bN97Pc-haAclf"></div><div class="ndfHFb-c4YZDc-cYSp0e-wxLEad-sn54Q" style="display: none;"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-gvZm2b"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-cYSp0e-oYxtQd-gvZm2b"></div></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf" style="padding-bottom: 131.375%;"><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-PLDbbf"></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-bN97Pc-haAclf"></div><div class="ndfHFb-c4YZDc-cYSp0e-wxLEad-sn54Q" style="display: none;"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-gvZm2b"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-cYSp0e-oYxtQd-gvZm2b"></div></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf" style="padding-bottom: 131.375%;"><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-PLDbbf"></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-bN97Pc-haAclf"></div><div class="ndfHFb-c4YZDc-cYSp0e-wxLEad-sn54Q" style="display: none;"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-gvZm2b"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-cYSp0e-oYxtQd-gvZm2b"></div></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf" style="padding-bottom: 131.375%;"><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-PLDbbf"></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-bN97Pc-haAclf"></div><div class="ndfHFb-c4YZDc-cYSp0e-wxLEad-sn54Q" style="display: none;"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-gvZm2b"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-cYSp0e-oYxtQd-gvZm2b"></div></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf" style="padding-bottom: 131.375%;"><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-PLDbbf"></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-bN97Pc-haAclf"></div><div class="ndfHFb-c4YZDc-cYSp0e-wxLEad-sn54Q" style="display: none;"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-gvZm2b"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-cYSp0e-oYxtQd-gvZm2b"></div></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf" style="padding-bottom: 131.375%;"><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-PLDbbf"></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-bN97Pc-haAclf"></div><div class="ndfHFb-c4YZDc-cYSp0e-wxLEad-sn54Q" style="display: none;"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-gvZm2b"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-cYSp0e-oYxtQd-gvZm2b"></div></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf" style="padding-bottom: 131.375%;"><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-PLDbbf"></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-bN97Pc-haAclf"></div><div class="ndfHFb-c4YZDc-cYSp0e-wxLEad-sn54Q" style="display: none;"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-gvZm2b"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-cYSp0e-oYxtQd-gvZm2b"></div></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf" style="padding-bottom: 131.375%;"><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-PLDbbf"></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-bN97Pc-haAclf"></div><div class="ndfHFb-c4YZDc-cYSp0e-wxLEad-sn54Q" style="display: none;"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-gvZm2b"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-cYSp0e-oYxtQd-gvZm2b"></div></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf" style="padding-bottom: 131.375%;"><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-PLDbbf"></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-bN97Pc-haAclf"></div><div class="ndfHFb-c4YZDc-cYSp0e-wxLEad-sn54Q" style="display: none;"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-gvZm2b"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-cYSp0e-oYxtQd-gvZm2b"></div></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf" style="padding-bottom: 131.375%;"><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-PLDbbf"></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-bN97Pc-haAclf"></div><div class="ndfHFb-c4YZDc-cYSp0e-wxLEad-sn54Q" style="display: none;"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-gvZm2b"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-cYSp0e-oYxtQd-gvZm2b"></div></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf" style="padding-bottom: 131.375%;"><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-PLDbbf"></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-bN97Pc-haAclf"></div><div class="ndfHFb-c4YZDc-cYSp0e-wxLEad-sn54Q" style="display: none;"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-gvZm2b"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-cYSp0e-oYxtQd-gvZm2b"></div></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf" style="padding-bottom: 131.375%;"><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-PLDbbf"></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-bN97Pc-haAclf"></div><div class="ndfHFb-c4YZDc-cYSp0e-wxLEad-sn54Q" style="display: none;"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-gvZm2b"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-cYSp0e-oYxtQd-gvZm2b"></div></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf" style="padding-bottom: 131.375%;"><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-PLDbbf"></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-bN97Pc-haAclf"></div><div class="ndfHFb-c4YZDc-cYSp0e-wxLEad-sn54Q" style="display: none;"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-gvZm2b"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-cYSp0e-oYxtQd-gvZm2b"></div></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf" style="padding-bottom: 131.375%;"><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-PLDbbf"></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-bN97Pc-haAclf"></div><div class="ndfHFb-c4YZDc-cYSp0e-wxLEad-sn54Q" style="display: none;"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-gvZm2b"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-cYSp0e-oYxtQd-gvZm2b"></div></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf" style="padding-bottom: 131.375%;"><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-PLDbbf"></div><div class="ndfHFb-c4YZDc-cYSp0e-DARUcf-Df1ZY-bN97Pc-haAclf"></div><div class="ndfHFb-c4YZDc-cYSp0e-wxLEad-sn54Q" style="display: none;"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-gvZm2b"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-vWsuo-fmcmS-G0jgYd"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-IDNFyf ndfHFb-c4YZDc-cYSp0e-oYxtQd-gvZm2b"></div></div></div><span class="ndfHFb-c4YZDc-cYSp0e-AznF2e-DTMEae" tabindex="0"></span></div><div class="ndfHFb-c4YZDc-n5VRYe-ma6Yeb" style="display: none;"></div><div class="ndfHFb-c4YZDc-n5VRYe-AeOLfc" style="display: none;"></div><div class="ndfHFb-c4YZDc-n5VRYe-cGMI2b" style="display: none;"></div><div class="ndfHFb-c4YZDc-n5VRYe-hOcTPc" style="display: none;"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-xxlfEe" aria-hidden="true"><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-xxlfEe-haAclf"><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-xxlfEe-YPqjbf-haAclf"><input class="ndfHFb-c4YZDc-vWsuo-fmcmS-xxlfEe-YPqjbf V67aGc-YPqjbf-V67aGc" placeholder="Find in document" aria-label="Find in document" tabindex="-1"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-xxlfEe-NnAfwf-haAclf"><span class="ndfHFb-c4YZDc-vWsuo-fmcmS-xxlfEe-NnAfwf"></span></div></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-xxlfEe-E7ORLb ndfHFb-c4YZDc-Bz112c ndfHFb-c4YZDc-vWsuo-fmcmS-xxlfEe-SKd3Ne VIpgJd-TzA9Ye-eEGnhe ndfHFb-c4YZDc-LgbsSe" role="button" style="-moz-user-select: none;" data-tooltip-unhoverable="true" data-tooltip-delay="500" data-tooltip-class="ndfHFb-c4YZDc-tk3N6e-suEOdc" data-tooltip-align="b,c" data-tooltip-offset="-6" aria-label="Find previous" data-tooltip="Find previous"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-xxlfEe-tJiF1e ndfHFb-c4YZDc-Bz112c ndfHFb-c4YZDc-vWsuo-fmcmS-xxlfEe-SKd3Ne VIpgJd-TzA9Ye-eEGnhe ndfHFb-c4YZDc-LgbsSe" role="button" style="-moz-user-select: none;" data-tooltip-unhoverable="true" data-tooltip-delay="500" data-tooltip-class="ndfHFb-c4YZDc-tk3N6e-suEOdc" data-tooltip-align="b,c" data-tooltip-offset="-6" aria-label="Find next" data-tooltip="Find next"></div><div class="ndfHFb-c4YZDc-vWsuo-fmcmS-xxlfEe-TvD9Pc ndfHFb-c4YZDc-Bz112c ndfHFb-c4YZDc-vWsuo-fmcmS-xxlfEe-SKd3Ne VIpgJd-TzA9Ye-eEGnhe ndfHFb-c4YZDc-LgbsSe" role="button" style="-moz-user-select: none;" data-tooltip-unhoverable="true" data-tooltip-delay="500" data-tooltip-class="ndfHFb-c4YZDc-tk3N6e-suEOdc" data-tooltip-align="b,c" data-tooltip-offset="-6" aria-label="Close find bar" data-tooltip="Close find bar"></div></div></div></div></div><div class="ndfHFb-c4YZDc-Wrql6b" role="toolbar" style="opacity: 1;"><div class="ndfHFb-c4YZDc-Wrql6b-SmKAyb" style="margin-right: 12px; padding-left: 12px;"><div class="ndfHFb-c4YZDc-Wrql6b-hOcTPc" style="left: 12px;"><div class="ndfHFb-c4YZDc-Wrql6b-Bz112c" tabindex="-1" role="img" style="background-image: url(&quot;//ssl.gstatic.com/docs/doclist/images/mediatype/icon_3_pdf_x16.png&quot;); background-position: left top; background-repeat: no-repeat;" aria-label="PDF icon"></div><div class="ndfHFb-c4YZDc-Wrql6b-jfdpUb" tabindex="-1"><div class="ndfHFb-c4YZDc-Wrql6b-V1ur5d" data-tooltip-unhoverable="true" data-tooltip-delay="500" data-tooltip-class="ndfHFb-c4YZDc-tk3N6e-suEOdc" data-tooltip-align="b,c" data-tooltip-offset="-6">AlphaGoNaturePaper.pdf</div><div class="ndfHFb-c4YZDc-Wrql6b-V1ur5d ndfHFb-c4YZDc-Wrql6b-V1ur5d-hpYHOb">AlphaGoNaturePaper.pdf</div><div class="ndfHFb-c4YZDc-Wrql6b-K4efff-V1ur5d" style="display: none;"></div><div class="ndfHFb-c4YZDc-Wrql6b-K4efff-V1ur5d ndfHFb-c4YZDc-Wrql6b-K4efff-V1ur5d-hpYHOb"></div></div><div class="ndfHFb-c4YZDc-Wrql6b-C7uZwb-b0t70b"></div></div><div class="ndfHFb-c4YZDc-Wrql6b-DdWCyb-b0t70b" style="display: none;"><div class="ndfHFb-c4YZDc-Wrql6b-FNFY6c-J42Xof-qMHh7d" style="display: none;"><div class="ndfHFb-c4YZDc-Wrql6b-FNFY6c ndfHFb-c4YZDc-to915-LgbsSe VIpgJd-TzA9Ye-eEGnhe ndfHFb-c4YZDc-LgbsSe" role="button" style="-moz-user-select: none; display: none;" data-tooltip-unhoverable="true" data-tooltip-delay="500" data-tooltip-class="ndfHFb-c4YZDc-tk3N6e-suEOdc" data-tooltip-align="b,c" data-tooltip-offset="-6" aria-hidden="true" aria-label="Open" data-tooltip="Open"><div class="ndfHFb-c4YZDc-FNFY6c-DWWcKd-Bz112c" style="display: none;"></div><div class="ndfHFb-c4YZDc-FNFY6c-V67aGc">Open</div></div><div class="ndfHFb-c4YZDc-Wrql6b-PlOyMe ndfHFb-c4YZDc-to915-LgbsSe VIpgJd-TzA9Ye-eEGnhe ndfHFb-c4YZDc-LgbsSe" role="button" style="-moz-user-select: none; display: none;" data-tooltip-unhoverable="true" data-tooltip-delay="500" data-tooltip-class="ndfHFb-c4YZDc-tk3N6e-suEOdc" data-tooltip-align="b,c" data-tooltip-offset="-6" aria-hidden="true"><div class="ndfHFb-c4YZDc-Wrql6b-PlOyMe-bN97Pc">Extract</div><div class="ndfHFb-c4YZDc-Wrql6b-HDMZaf-Bz112c"><div class="ndfHFb-aZ2wEe" dir="ltr"><div class="ndfHFb-vyDMJf-aZ2wEe auswjd"><div class="aZ2wEe-pbTTYe aZ2wEe-v3pZbf"><div class="aZ2wEe-LkdAo-e9ayKc aZ2wEe-LK5yu"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div><div class="aZ2wEe-pehrl-TpMipd"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div><div class="aZ2wEe-LkdAo-e9ayKc aZ2wEe-qwU8Me"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div></div><div class="aZ2wEe-pbTTYe aZ2wEe-oq6NAc"><div class="aZ2wEe-LkdAo-e9ayKc aZ2wEe-LK5yu"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div><div class="aZ2wEe-pehrl-TpMipd"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div><div class="aZ2wEe-LkdAo-e9ayKc aZ2wEe-qwU8Me"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div></div><div class="aZ2wEe-pbTTYe aZ2wEe-gS7Ybc"><div class="aZ2wEe-LkdAo-e9ayKc aZ2wEe-LK5yu"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div><div class="aZ2wEe-pehrl-TpMipd"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div><div class="aZ2wEe-LkdAo-e9ayKc aZ2wEe-qwU8Me"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div></div><div class="aZ2wEe-pbTTYe aZ2wEe-nllRtd"><div class="aZ2wEe-LkdAo-e9ayKc aZ2wEe-LK5yu"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div><div class="aZ2wEe-pehrl-TpMipd"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div><div class="aZ2wEe-LkdAo-e9ayKc aZ2wEe-qwU8Me"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div></div></div></div></div></div><div class="ndfHFb-c4YZDc-Wrql6b-qMHh7d ndfHFb-c4YZDc-to915-LgbsSe VIpgJd-TzA9Ye-eEGnhe ndfHFb-c4YZDc-LgbsSe" role="button" style="-moz-user-select: none; display: none;" aria-expanded="false" aria-haspopup="true" data-tooltip-unhoverable="true" data-tooltip-delay="500" data-tooltip-class="ndfHFb-c4YZDc-tk3N6e-suEOdc" data-tooltip-align="b,c" data-tooltip-offset="-6" aria-label="Open with" data-tooltip="Open with" aria-hidden="true"><div class="ndfHFb-c4YZDc-Wrql6b-FNFY6c-hgDUwe"></div><div class="ndfHFb-c4YZDc-Wrql6b-qMHh7d-SmKAyb"><div class="ndfHFb-c4YZDc-Wrql6b-qMHh7d-fmcmS" tabindex="-1">Open with</div><div class="ndfHFb-c4YZDc-Wrql6b-xl07Ob-LgbsSe-hFsbo"><div class="ndfHFb-c4YZDc-Bz112c"></div></div></div></div></div><div class="ndfHFb-c4YZDc-Wrql6b-C7uZwb-b0t70b"></div></div><div class="ndfHFb-c4YZDc-Wrql6b-AeOLfc-b0t70b"><div class="ndfHFb-c4YZDc-GSQQnc-LgbsSe ndfHFb-c4YZDc-to915-LgbsSe" aria-label="Pop out" style="display: none;"><div class="ndfHFb-c4YZDc-Bz112c ndfHFb-c4YZDc-DH6Rkf-Bz112c"></div></div><div class="ndfHFb-c4YZDc-Wrql6b-LQLjdd"><div class="ndfHFb-c4YZDc-Wrql6b-htvI8d-wcotoc-ndfHFb ndfHFb-c4YZDc-to915-LgbsSe" style="display: none;"><div><div class="ndfHFb-aZ2wEe" dir="ltr"><div class="ndfHFb-vyDMJf-aZ2wEe auswjd"><div class="aZ2wEe-pbTTYe aZ2wEe-v3pZbf"><div class="aZ2wEe-LkdAo-e9ayKc aZ2wEe-LK5yu"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div><div class="aZ2wEe-pehrl-TpMipd"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div><div class="aZ2wEe-LkdAo-e9ayKc aZ2wEe-qwU8Me"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div></div><div class="aZ2wEe-pbTTYe aZ2wEe-oq6NAc"><div class="aZ2wEe-LkdAo-e9ayKc aZ2wEe-LK5yu"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div><div class="aZ2wEe-pehrl-TpMipd"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div><div class="aZ2wEe-LkdAo-e9ayKc aZ2wEe-qwU8Me"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div></div><div class="aZ2wEe-pbTTYe aZ2wEe-gS7Ybc"><div class="aZ2wEe-LkdAo-e9ayKc aZ2wEe-LK5yu"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div><div class="aZ2wEe-pehrl-TpMipd"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div><div class="aZ2wEe-LkdAo-e9ayKc aZ2wEe-qwU8Me"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div></div><div class="aZ2wEe-pbTTYe aZ2wEe-nllRtd"><div class="aZ2wEe-LkdAo-e9ayKc aZ2wEe-LK5yu"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div><div class="aZ2wEe-pehrl-TpMipd"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div><div class="aZ2wEe-LkdAo-e9ayKc aZ2wEe-qwU8Me"><div class="aZ2wEe-LkdAo aZ2wEe-hj4D6d"></div></div></div></div></div></div></div><div class="ndfHFb-c4YZDc-Wrql6b-C7uZwb-b0t70b"><div class="ndfHFb-c4YZDc-to915-LgbsSe ndfHFb-c4YZDc-C7uZwb-LgbsSe VIpgJd-TzA9Ye-eEGnhe ndfHFb-c4YZDc-LgbsSe ndfHFb-c4YZDc-C7uZwb-LgbsSe-SfQLQb-Bz112c" role="button" style="-moz-user-select: none;" data-tooltip-unhoverable="true" data-tooltip-delay="500" data-tooltip-class="ndfHFb-c4YZDc-tk3N6e-suEOdc" data-tooltip-align="b,c" data-tooltip-offset="-6" aria-disabled="false" aria-hidden="false" aria-label="Print" tabindex="0" data-tooltip="Print"><div class="ndfHFb-c4YZDc-Bz112c ndfHFb-c4YZDc-C7uZwb-LgbsSe-Bz112c ndfHFb-c4YZDc-PEFSMe-Bz112c"></div></div><div class="ndfHFb-c4YZDc-to915-LgbsSe ndfHFb-c4YZDc-C7uZwb-LgbsSe VIpgJd-TzA9Ye-eEGnhe ndfHFb-c4YZDc-LgbsSe ndfHFb-c4YZDc-C7uZwb-LgbsSe-SfQLQb-Bz112c" role="button" style="-moz-user-select: none;" tabindex="0" data-tooltip-unhoverable="true" data-tooltip-delay="500" data-tooltip-class="ndfHFb-c4YZDc-tk3N6e-suEOdc" data-tooltip-align="b,c" data-tooltip-offset="-6" aria-label="Open original" data-tooltip="Open original"><div class="ndfHFb-c4YZDc-Bz112c ndfHFb-c4YZDc-C7uZwb-LgbsSe-Bz112c ndfHFb-c4YZDc-FNFY6c-bEDTcc-oxvKad-Bz112c"></div></div><div class="ndfHFb-c4YZDc-z5C9Gb-LgbsSe ndfHFb-c4YZDc-to915-LgbsSe VIpgJd-TzA9Ye-eEGnhe ndfHFb-c4YZDc-LgbsSe" role="button" style="-moz-user-select: none; display: none;" aria-expanded="false" aria-haspopup="true" data-tooltip-unhoverable="true" data-tooltip-delay="500" data-tooltip-class="ndfHFb-c4YZDc-tk3N6e-suEOdc" data-tooltip-align="b,c" data-tooltip-offset="-6" aria-label="More actions" data-tooltip="More actions" aria-hidden="true"><div class="ndfHFb-c4YZDc-Bz112c"></div></div></div></div><div class="ndfHFb-c4YZDc-mKZypf-bEDTcc"><div class="ndfHFb-c4YZDc-mKZypf-bEDTcc-LgbsSe tk3N6e-LgbsSe tk3N6e-LgbsSe-JIbuQc" role="button" style="-moz-user-select: none;" tabindex="0">Sign In</div></div></div></div></div></div><span class="ndfHFb-c4YZDc-AznF2e-DTMEae" style="" tabindex="0" aria-hidden="true"></span><iframe id="apiproxy10443c113580f408b308c26fa19fc6f64a2111ff0.737308638" name="apiproxy10443c113580f408b308c26fa19fc6f64a2111ff0.737308638" style="width: 1px; height: 1px; position: absolute; top: -100px; display: none;" src="AlphaGoNaturePaper_files/proxy.html" tabindex="-1" aria-hidden="true"></iframe><div style="position: absolute; top: -1000px; height: 1px; overflow: hidden;" aria-live="polite" aria-atomic="true">Displaying AlphaGoNaturePaper.pdf.</div><div class="ndfHFb-c4YZDc-mg9Pef ndfHFb-c4YZDc-mg9Pef-BvBYQ ndfHFb-c4YZDc-i5oIFb" style="-moz-user-select: none; display: none;" role="menu" aria-haspopup="true" tabindex="-1"><div class="ndfHFb-c4YZDc-j7LFlb" role="menuitem" style="-moz-user-select: none;" id=":41"><div class="ndfHFb-c4YZDc-j7LFlb-bN97Pc">Copy</div></div></div></body></html>